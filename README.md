# Feature-Selection-using-Catboost
Subsequent increase in data dimension have driven the need for feature engineering techniques to tackle feature redundancy and enhance explainable machine learning approaches using several feature selection techniques based on filter, wrapper, and embedded approaches. In this, I have created feature selection using CatBoost. The thought process of building trees in CatBoost was used for reference, and the importance of features from three importance metrics was measured to avoid the limitation of single importance metric.
